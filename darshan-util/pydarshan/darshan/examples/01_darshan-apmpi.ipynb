{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DarshanUtils for Python\n",
    "\n",
    "This notebook gives an overwiew of features provided by the Python bindings for DarshanUtils."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default all records, metadata, available modules and the name records are loaded when opening a Darshan log:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/lib/\n"
     ]
    }
   ],
   "source": [
    "%env LD_LIBRARY_PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PE_PKGCONFIG_LIBS=darshan-runtime\n",
      "env: PKG_CONFIG_PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/lib/pkgconfig\n",
      "env: PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-utils/bin:/opt/anaconda3x/bin:/opt/anaconda3x/condabin:/projects/Performance/chunduri/Work_backup_June252017/software/install/autotools/bin:/bin:/sbin:/opt/anaconda3x/bin:/usr/bin/usr/sbin:/usr/local/sbin:/usr/sbin:/dbhome/db2cat/sqllib/bin:/dbhome/db2cat/sqllib/adm:/dbhome/db2cat/sqllib/misc:/dbhome/db2cat/sqllib/gskit/bin:/opt/ibutils/bin:/home/chunduri/bin:/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/bin\n"
     ]
    }
   ],
   "source": [
    "%env PE_PKGCONFIG_LIBS=darshan-runtime \n",
    "%env PKG_CONFIG_PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/lib/pkgconfig \n",
    "%env PATH=/projects/Performance/chunduri/Software/Temp/build/darshan-utils/bin:/opt/anaconda3x/bin:/opt/anaconda3x/condabin:/projects/Performance/chunduri/Work_backup_June252017/software/install/autotools/bin:/bin:/sbin:/opt/anaconda3x/bin:/usr/bin/usr/sbin:/usr/local/sbin:/usr/sbin:/dbhome/db2cat/sqllib/bin:/dbhome/db2cat/sqllib/adm:/dbhome/db2cat/sqllib/misc:/dbhome/db2cat/sqllib/gskit/bin:/opt/ibutils/bin:/home/chunduri/bin:/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: darshan_prefix=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/install\n",
      "env: darshan_share=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/install/share\n",
      "env: darshan_libdir=-L${darshan_prefix}/lib\n"
     ]
    }
   ],
   "source": [
    "%env darshan_prefix=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/install\n",
    "%env darshan_share=/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/install/share\n",
    "%env darshan_libdir= -L${darshan_prefix}/lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/lib/\n",
      "/projects/Performance/chunduri/Software/Temp/build/darshan-utils/bin:/opt/anaconda3x/bin:/opt/anaconda3x/condabin:/projects/Performance/chunduri/Work_backup_June252017/software/install/autotools/bin:/bin:/sbin:/opt/anaconda3x/bin:/usr/bin/usr/sbin:/usr/local/sbin:/usr/sbin:/dbhome/db2cat/sqllib/bin:/dbhome/db2cat/sqllib/adm:/dbhome/db2cat/sqllib/misc:/dbhome/db2cat/sqllib/gskit/bin:/opt/ibutils/bin:/home/chunduri/bin:/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/bin\n",
      "/projects/Performance/chunduri/Software/Temp/build/darshan-runtime/lib/pkgconfig\n"
     ]
    }
   ],
   "source": [
    "!echo $LD_LIBRARY_PATH\n",
    "!echo $PATH\n",
    "!echo $PKG_CONFIG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/lus/theta-fs0/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples\n",
      "/lus/theta-fs0/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan\n",
      "/lus/theta-fs0/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "%cd ..\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cffi\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib\n",
    "import pprint\n",
    "# ffi = cffi.FFI()\n",
    "# libdutil = ffi.dlopen(\"/projects/Performance/chunduri/Software/Temp/build/darshan-util/install/lib/libdarshan-util.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darshan.backend.cffi_backend import ffi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logger\n",
    "from darshan.report import DarshanReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan.backend.cffi_backend as backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:       /projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/498873.128.64p.log\n",
      "Times:          2021-02-17 11:19:42 to 2021-02-17 11:33:58 (Duration 0:14:16)\n",
      "Executeable:    /lus/theta-fs0/projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/../milc_qcd-git-201510211317/ks_imp_rhmc/su3_rhmd_hisq /lus/theta-fs0/projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/../runs/l9648_4steps.in\n",
      "Processes:      8192\n",
      "JobID:          498873\n",
      "UID:            32451\n",
      "Modules in Log: ['LUSTRE', 'STDIO', 'APXC', 'APMPI']\n",
      "Loaded Records: {}\n",
      "Name Records:   0\n",
      "Darshan/Hints:  {'lib_ver': '3.2.1', 'h': 'romio_no_indep_rw=true;cb_nodes=4'}\n",
      "DarshanReport:  id(140383593345616) (tmp)\n"
     ]
    }
   ],
   "source": [
    "#import darshan\n",
    "\n",
    "#report = darshan.DarshanReport(\"examples/example-logs/example.darshan\", read_all=True)  # Default behavior\n",
    "#report = darshan.DarshanReport(\"/projects/Performance/chunduri/Work/3D-7PointStencil-MPI/496119.2.2p.log\", read_all=False) \n",
    "report = darshan.DarshanReport(\"/projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/498873.128.64p.log\", read_all=False)\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APMPI-HEADER\n",
      "struct darshan_apmpi_header_record **\n"
     ]
    }
   ],
   "source": [
    "r = report.mod_read_all_apmpi_records(\"APMPI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['version', 'metadata', 'records', 'summary', 'modules', 'counters', 'name_records', 'mounts'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename:       /projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/498873.128.64p.log\n",
      "Times:          2021-02-17 11:19:42 to 2021-02-17 11:33:58 (Duration 0:14:16)\n",
      "Executeable:    /lus/theta-fs0/projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/../milc_qcd-git-201510211317/ks_imp_rhmc/su3_rhmd_hisq /lus/theta-fs0/projects/Performance/chunduri/MILC/milctestv2-papi-reorder-darshan/MILC_128_498873/../runs/l9648_4steps.in\n",
      "Processes:      8192\n",
      "JobID:          498873\n",
      "UID:            32451\n",
      "Modules in Log: ['LUSTRE', 'STDIO', 'APXC', 'APMPI']\n",
      "Loaded Records: {'APMPI': 8193}\n",
      "Name Records:   2\n",
      "Darshan/Hints:  {'lib_ver': '3.2.1', 'h': 'romio_no_indep_rw=true;cb_nodes=4'}\n",
      "DarshanReport:  id(140383593345616) (tmp)\n"
     ]
    }
   ],
   "source": [
    "report.update_name_records()\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3x/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1613589051.1455183 539.32\n",
      "# darshan log version:  1\n",
      "APMPI Variance in total mpi time:  96.16168403248518 \n",
      "\n",
      "       Rank   Node_ID           Call  Total_Time    Count  Total_Bytes  \\\n",
      "0         0  nid00920       MPI_WAIT  216.377984  2607364         None   \n",
      "1         0  nid00920  MPI_ALLREDUCE  129.520685   157515      1260012   \n",
      "2         0  nid00920      MPI_ISEND   20.172348  1303682  30953347840   \n",
      "3         0  nid00920      MPI_IRECV    6.696055  1303682  30953347840   \n",
      "4         0  nid00920     MPI_REDUCE    0.987648        1            8   \n",
      "...     ...       ...            ...         ...      ...          ...   \n",
      "57339  8191  nid04603      MPI_ISEND   17.356476  1303682  30953347840   \n",
      "57340  8191  nid04603      MPI_IRECV    5.852337  1303682  30953347840   \n",
      "57341  8191  nid04603      MPI_BCAST    0.099630      104         8140   \n",
      "57342  8191  nid04603    MPI_BARRIER    0.039288        2         None   \n",
      "57343  8191  nid04603     MPI_REDUCE    0.000042        1            8   \n",
      "\n",
      "      [0-256B] [256-1KB] [1K-8KB] [8K-256KB] 256K-1MB [>1MB]  Min_Time  \\\n",
      "0         None      None     None       None     None   None  0.000002   \n",
      "1       157515         0        0          0        0      0  0.000090   \n",
      "2           16         0     5624    1298042        0      0  0.000003   \n",
      "3           16         0     5624    1298042        0      0  0.000002   \n",
      "4            1         0        0          0        0      0  0.987648   \n",
      "...        ...       ...      ...        ...      ...    ...       ...   \n",
      "57339       16         0     5624    1298042        0      0  0.000004   \n",
      "57340       16         0     5624    1298042        0      0  0.000002   \n",
      "57341      101         0        3          0        0      0  0.000004   \n",
      "57342     None      None     None       None     None   None  0.009431   \n",
      "57343        1         0        0          0        0      0  0.000042   \n",
      "\n",
      "       Max_Time  \n",
      "0      0.022655  \n",
      "1      0.271192  \n",
      "2      0.002505  \n",
      "3      0.001940  \n",
      "4      0.987648  \n",
      "...         ...  \n",
      "57339  0.003165  \n",
      "57340  0.003266  \n",
      "57341  0.027544  \n",
      "57342  0.029857  \n",
      "57343  0.000042  \n",
      "\n",
      "[57344 rows x 14 columns]\n",
      "1613589334.4497185 822.67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3x/lib/python3.7/site-packages/ipykernel_launcher.py:63: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "len(report.records['APMPI'])\n",
    "rec = report.records['APMPI'][0]\n",
    "import time\n",
    "print(time.time(), time.clock())\n",
    "print(\"# darshan log version: \", rec['version'])\n",
    "sync_flag = rec['sync_flag']\n",
    "\n",
    "print(\"APMPI Variance in total mpi time: \", rec['variance_total_mpitime'], \"\\n\")\n",
    "if sync_flag:\n",
    "    print(\"APMPI Variance in total mpi sync time: \", rec['variance_total_mpisynctime'])\n",
    "\n",
    "df_apmpi = pd.DataFrame()\n",
    "for rec in report.records['APMPI'][1:]:   #skip the first record which is header\n",
    "    mpi_nonzero_callcount = []\n",
    "    for k,v in rec['all_counters'].items():\n",
    "        if k.endswith('_CALL_COUNT') and v>0:\n",
    "            mpi_nonzero_callcount.append(k[:-(len('CALL_COUNT'))])\n",
    "\n",
    "    df_rank = pd.DataFrame()\n",
    "    for mpiop in mpi_nonzero_callcount:\n",
    "        ncall = mpiop\n",
    "        #print(mpiop)\n",
    "        ncount = mpiop + 'CALL_COUNT'\n",
    "        nsize  = mpiop + 'TOTAL_BYTES'\n",
    "        h0     = mpiop + 'MSG_SIZE_AGG_0_256'\n",
    "        h1     = mpiop + 'MSG_SIZE_AGG_256_1K'\n",
    "        h2     = mpiop + 'MSG_SIZE_AGG_1K_8K'\n",
    "        h3     = mpiop + 'MSG_SIZE_AGG_8K_256K'\n",
    "        h4     = mpiop + 'MSG_SIZE_AGG_256K_1M'\n",
    "        h5     = mpiop + 'MSG_SIZE_AGG_1M_PLUS'\n",
    "        ntime  = mpiop + 'TOTAL_TIME'\n",
    "        mintime  = mpiop + 'MIN_TIME'\n",
    "        maxtime  = mpiop + 'MAX_TIME'\n",
    "        if sync_flag:\n",
    "            totalsync = mpiop + 'TOTAL_SYNC_TIME'\n",
    "        \n",
    "        mpiopstat = {}\n",
    "        mpiopstat['Rank'] = rec['rank']\n",
    "        mpiopstat['Node_ID'] = rec['node_name']\n",
    "        mpiopstat['Call'] = ncall[:-1]\n",
    "        mpiopstat['Total_Time'] = rec['all_counters'][ntime]\n",
    "        mpiopstat['Count'] = rec['all_counters'][ncount]\n",
    "        mpiopstat['Total_Bytes'] = rec['all_counters'].get(nsize, None)\n",
    "        mpiopstat['[0-256B]'] = rec['all_counters'].get(h0, None)\n",
    "        mpiopstat['[256-1KB]'] = rec['all_counters'].get(h1, None)\n",
    "        mpiopstat['[1K-8KB]'] = rec['all_counters'].get(h2, None)\n",
    "        mpiopstat['[8K-256KB]'] = rec['all_counters'].get(h3, None)\n",
    "        mpiopstat['256K-1MB'] = rec['all_counters'].get(h4, None)\n",
    "        mpiopstat['[>1MB]'] = rec['all_counters'].get(h5, None)\n",
    "        mpiopstat['Min_Time'] = rec['all_counters'][mintime]\n",
    "        mpiopstat['Max_Time'] = rec['all_counters'][maxtime]\n",
    "        if sync_flag:\n",
    "            mpiopstat[\"Total_SYNC_Time\"] = rec['all_counters'][totalsync]\n",
    "            \n",
    "        df_mpiop  = pd.DataFrame([mpiopstat], columns=mpiopstat.keys())\n",
    "        df_rank = pd.concat([df_rank, df_mpiop], axis =0).reset_index(drop=True)\n",
    "        #sort data frame based on MPIOP total time\n",
    "    \n",
    "    df_rank = df_rank.sort_values(by=['Total_Time'], ascending=False)  \n",
    "    df_apmpi = pd.concat([df_apmpi, df_rank], axis=0).reset_index(drop=True)\n",
    "print(df_apmpi)\n",
    "print(time.time(), time.clock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "len(report.records['APMPI'])\n",
    "rec = report.records['APMPI'][0]\n",
    "\n",
    "print(\"# darshan log version: \", rec['version'])\n",
    "sync_flag = rec['sync_flag']\n",
    "\n",
    "print(\"APMPI Variance in total mpi time: \", rec['variance_total_mpitime'], \"\\n\")\n",
    "if sync_flag:\n",
    "    print(\"APMPI Variance in total mpi sync time: \", rec['variance_total_mpisynctime'])\n",
    "\n",
    "if sync_flag:\n",
    "    print(\"{:<8}{:<10}{:<16}{:<18}{:<10}{:<15}{:<10}{:<10}{:<10}{:<10}{:<10}{:<10}{:<18}{:<18}{:<18}\\n{}\".format(\n",
    "    \"Rank\",\"Node_ID\", \"Call\", \"Total_Time\", \"Count\", \"Total_Bytes\", \"0-256\", \"256-1K\", \"1K-8K\", \"8K-256K\", \"256K-1M\", \"1M+\", \n",
    "    \"Min_Time\", \"Max_Time\", \"Total_SYNC_Time\", \"=\"*180))\n",
    "else:\n",
    "    print(\"{:<8}{:<10}{:<16}{:<18}{:<10}{:<15}{:<10}{:<10}{:<10}{:<10}{:<10}{:<10}{:<18}{:<18}\\n{}\".format(\n",
    "    \"Rank\",\"Node_ID\", \"Call\", \"Total_Time\", \"Count\", \"Total_Bytes\", \"0-256\", \"256-1K\", \"1K-8K\", \"8K-256K\", \"256K-1M\", \"1M+\", \n",
    "     \"Min_Time\", \"Max_Time\", \"=\"*180))\n",
    "\n",
    "\n",
    "for rec in report.records['APMPI'][1:]:   #skip the first record which is header\n",
    "    \n",
    "    mpi_nonzero_callcount = []\n",
    "    for k,v in rec['all_counters'].items():\n",
    "        if k.endswith('_CALL_COUNT') and v>0:\n",
    "            mpi_nonzero_callcount.append(k[:-(len('CALL_COUNT'))])\n",
    "\n",
    "    \n",
    "    for mpiop in mpi_nonzero_callcount:\n",
    "        ncall = mpiop\n",
    "        ncount = mpiop + 'CALL_COUNT'\n",
    "        nsize  = mpiop + 'TOTAL_BYTES'\n",
    "        h0     = mpiop + 'MSG_SIZE_AGG_0_256'\n",
    "        h1     = mpiop + 'MSG_SIZE_AGG_256_1K'\n",
    "        h2     = mpiop + 'MSG_SIZE_AGG_1K_8K'\n",
    "        h3     = mpiop + 'MSG_SIZE_AGG_8K_256K'\n",
    "        h4     = mpiop + 'MSG_SIZE_AGG_256K_1M'\n",
    "        h5     = mpiop + 'MSG_SIZE_AGG_1M_PLUS'\n",
    "        ntime  = mpiop + 'TOTAL_TIME'\n",
    "        mintime  = mpiop + 'MIN_TIME'\n",
    "        maxtime  = mpiop + 'MAX_TIME'\n",
    "        if sync_flag:\n",
    "            totalsync = mpiop + 'TOTAL_SYNC_TIME'\n",
    "        \n",
    "        if (rec['all_counters'][ncount] > 0 or not args.quiet):\n",
    "            print(\"{rank:<8}{node_name:<10}{call:<16}{ntime:<18.6f}{count:<10}{size:<15}{h0:<10}{h1:<10}{h2:<10}{h3:<10}{h4:<10}{h5:<10}{mintime:<18.6f}{maxtime:<18.6f}\".format(\n",
    "            rank = rec['rank'],\n",
    "            node_name = rec['node_name'],\n",
    "            call = ncall[:-1],\n",
    "            ntime = rec['all_counters'].get(ntime, 'NA'),\n",
    "            count = rec['all_counters'][ncount],\n",
    "            size = rec['all_counters'].get(nsize, 'NA'),\n",
    "            h0 = rec['all_counters'].get(h0, 'NA'),\n",
    "            h1 = rec['all_counters'].get(h1, 'NA'),\n",
    "            h2 = rec['all_counters'].get(h2, 'NA'),\n",
    "            h3 = rec['all_counters'].get(h3, 'NA'),\n",
    "            h4 = rec['all_counters'].get(h4, 'NA'),\n",
    "            h5 = rec['all_counters'].get(h5, 'NA'),\n",
    "            mintime = rec['all_counters'].get(mintime, 'NA'),\n",
    "            maxtime = rec['all_counters'].get(maxtime, 'NA')), end='')\n",
    "            if sync_flag:\n",
    "                print(\"{totalsync:18.6f}\".format( totalsync = rec['all_counters'][totalsync]))\n",
    "            print(\" \")\n",
    "            \n",
    "    print(\"{rank:<8}{node_name:<10}{call:<16}{time:<18.6f}\".format(\n",
    "        rank = rec['rank'],\n",
    "        node_name = rec['node_name'],\n",
    "        call = \"Total_MPI_time\",\n",
    "        time=rec['all_counters']['RANK_TOTAL_MPITIME']\n",
    "        )) \n",
    "    #print(\"Rank\", rec['rank'], \"Total_MPI_time: \", rec['all_counters']['RANK_TOTAL_MPITIME'])\n",
    "    if sync_flag:\n",
    "        print(\"Rank\", rec['rank'], \"Total_MPI_SYNC_time: \", rec['all_counters']['RANK_TOTAL_MPISYNCTIME'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'rank', 'node_name', 'all_counters'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('MPI_ALLREDUCE_CALL_COUNT', 1253735),\n",
       " ('MPI_ALLREDUCE_TOTAL_BYTES', 10029388),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_0_256', 1253735),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_256_1K', 0),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_1K_8K', 0),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_8K_256K', 0),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_256K_1M', 0),\n",
       " ('MPI_ALLREDUCE_MSG_SIZE_AGG_1M_PLUS', 0),\n",
       " ('MPI_ALLREDUCE_TOTAL_TIME', 55.16067552566528),\n",
       " ('MPI_ALLREDUCE_MIN_TIME', 2.5033950805664062e-05),\n",
       " ('MPI_ALLREDUCE_MAX_TIME', 0.007993221282958984),\n",
       " ('MPI_ALLREDUCE_TOTAL_SYNC_TIME', 101.60499858856201)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pp.pprint(report.records['APMPI'][0]['all_counters'])\n",
    "\n",
    "pp.pprint(report.records['APMPI'][0].keys())\n",
    "[ (k,v) for k,v in report.records['APMPI'][0]['all_counters'].items() if k.startswith('MPI_ALLREDUCE_')]\n",
    "\n",
    "#[ (k,v) for k,v in report.records['APMPI'][0]['all_counters'].items() if k.endswith('_CALL_COUNT')]\n",
    "\n",
    "# for k,v in report.records['APMPI'][0]['all_counters'].items():\n",
    "#     if k.endswith('_CALL_COUNT') and v>0:\n",
    "#         print(k,v)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MPI_SEND_', 'MPI_RECV_']\n",
      "MPI_SEND_CALL_COUNT 900\n",
      "MPI_SEND_TOTAL_BYTES 629146800\n",
      "MPI_SEND_MSG_SIZE_AGG_0_256 300\n",
      "MPI_SEND_MSG_SIZE_AGG_256_1K 0\n",
      "MPI_SEND_MSG_SIZE_AGG_1K_8K 0\n",
      "MPI_SEND_MSG_SIZE_AGG_8K_256K 0\n",
      "MPI_SEND_MSG_SIZE_AGG_256K_1M 600\n",
      "MPI_SEND_MSG_SIZE_AGG_1M_PLUS 0\n",
      "MPI_SEND_TOTAL_TIME 0.3348836898803711\n",
      "MPI_SEND_MIN_TIME 5.9604644775390625e-06\n",
      "MPI_SEND_MAX_TIME 0.10425710678100586\n",
      "MPI_RECV_CALL_COUNT 900\n",
      "MPI_RECV_TOTAL_BYTES 629146800\n",
      "MPI_RECV_MSG_SIZE_AGG_0_256 300\n",
      "MPI_RECV_MSG_SIZE_AGG_256_1K 0\n",
      "MPI_RECV_MSG_SIZE_AGG_1K_8K 0\n",
      "MPI_RECV_MSG_SIZE_AGG_8K_256K 0\n",
      "MPI_RECV_MSG_SIZE_AGG_256K_1M 600\n",
      "MPI_RECV_MSG_SIZE_AGG_1M_PLUS 0\n",
      "MPI_RECV_TOTAL_TIME 0.2742795944213867\n",
      "MPI_RECV_MIN_TIME 2.86102294921875e-06\n",
      "MPI_RECV_MAX_TIME 0.15262413024902344\n"
     ]
    }
   ],
   "source": [
    "[k for k in report.records['APMPI'][0]['all_counters'].keys() if k.startswith('MPI_SEND_')]\n",
    "\n",
    "mpi_nonzero_callcount = []\n",
    "for k,v in report.records['APMPI'][0]['all_counters'].items():\n",
    "    if k.endswith('_CALL_COUNT') and v>0:\n",
    "        mpi_nonzero_callcount.append(k[:-(len('CALL_COUNT'))])\n",
    "print(mpi_nonzero_callcount)\n",
    "for mpiop in mpi_nonzero_callcount:\n",
    "    for k in report.records['APMPI'][0]['all_counters'].keys():\n",
    "        if k.startswith(mpiop):\n",
    "            print(k, report.records['APMPI'][0]['all_counters'][k])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few of the internal data structures explained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# report.metadata         # dictionary with raw metadata from darshan log\n",
    "# report.modules          # dictionary with raw module info from darshan log (need: technical, module idx)\n",
    "# report.name_records     # dictionary for resovling name records: id -> path/name\n",
    "# report.records          # per module \"dataframes\"/dictionaries holding loaded records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The darshan report holds a variety of namespaces for report related data. All of them are also referenced in `report.data` at the moment, but reliance on this internal organization of the report object is discouraged once the API stabilized. Currently, `report.data` references the following information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report.data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records('POSIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records('STDIO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.update_name_records()\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization helper used by different examples in the remainder of this notebook\n",
    "from IPython.display import display, HTML\n",
    "# usage: display(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Record Formats and Selectively Loading Records\n",
    "\n",
    "For memory efficiant analysis, it is possible to supress records from being loaded automatically. This is useful, for example, when analysis considers only records of a particular layer/module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "report = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\", read_all=False, lookup_name_records=True) # Loads no records!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected to fail, as no records were loaded\n",
    "try:\n",
    "    print(len(report.records['STDIO']), \"records loaded for STDIO.\")\n",
    "except:\n",
    "    print(\"No STDIO records loaded for this report yet.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional records then can be loaded selectively, for example, on a per module basis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\", dtype=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('id', report.records['STDIO'][0]['id'])\n",
    "print('rank', report.records['STDIO'][0]['rank'])\n",
    "display(report.records['STDIO'][0]['counters'])\n",
    "display(report.records['STDIO'][0]['fcounters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\", dtype='dict')\n",
    "report.records['STDIO'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dtype: numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"STDIO\")\n",
    "report.records['STDIO'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Log in Memory\n",
    "\n",
    "Let's have a look at how calling `report.mod_read_all_records(\"STDIO\")` changed the state of the log in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to info line: \"Loaded Records: {...}\"\n",
    "report.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interacting on individual log data for example in a for loop you would most likely care about the following instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num records:\", len(report.records['STDIO']))\n",
    "\n",
    "# show first 10 records\n",
    "for rec in report.records['STDIO'][0:10]:\n",
    "    print(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation and Filtering (Experimental)\n",
    "\n",
    "Darshan log data is routinely aggregated for quick overview. The report object offers a few methods to perform common aggregations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report aggregations and summarization remains**experimental** for now, mostly to allow interfaces to stabilize. But experimental features can be switched on easily by invoking `darshan.enable_experimental()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=True) # Enable verbosity, listing new functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example report, which counts records in log across modules \n",
    "report.name_records_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain operations like filtering and reductions\n",
    "The filter and reduce operations return DarshanReports themsleves, thus allow to convieniently chain operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "import darshan\n",
    "darshan.enable_experimental()\n",
    "\n",
    "report = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\", read_all=True)\n",
    "report.name_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report.filter(name_records=[6301063301082038805, 15920181672442173319]).records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# reduce all after filtering\n",
    "report.filter(pattern=\"*.hdf5\").reduce().records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only preserve some\n",
    "report.filter(name_records=[6301063301082038805]).reduce(mods=['POSIX', 'STDIO']).records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# expected to fail\n",
    "try:\n",
    "    pprint.pprint(report.summary['agg_ioops'])\n",
    "except:\n",
    "    print(\"IOOPS have not been aggregated for this report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.read_all() \n",
    "report.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report.summary['agg_ioops']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or fine grained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_agg_iohist(\"MPI-IO\")  # to create the histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.agg_ioops()               # to create the combined operation type summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report Algebra (Experimental)\n",
    "\n",
    "Various operations are implemented to merge, combine and manipulate log records. This is useful for analysis task, but can also be used to construct performance projections or extrapolation.\n",
    "\n",
    "For convienience, we overload some of the operations provided by Python when they resemble intuitive equivalence to their mathematical counterparts. In particular, we enable the combination of different object types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merging records\n",
    "from darshan.experimental.plots.matplotlib import plot_access_histogram\n",
    "from darshan.experimental.plots.matplotlib import plot_opcounts\n",
    "\n",
    "r1 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\", read_all=True)\n",
    "r2 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example2.darshan\", read_all=True)\n",
    "rx = r1 + r2\n",
    "\n",
    "for r in [r1, r2, rx]:\n",
    "    plt = plot_opcounts(r)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiply records with a scalar (think, four times the I/O load)\n",
    "#r1 = darshan.DarshanReport(\"example.darshan\", read_all=True)\n",
    "#rx = r1 * 4\n",
    "#plot_opcounts(rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rebase via timedelta\n",
    "#r1 = darshan.DarshanReport(\"example.darshan\", read_all=True)\n",
    "#dt = datetime.timedelta()\n",
    "#rx = r1 + dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\")\n",
    "r3.mod_read_all_records('POSIX')\n",
    "\n",
    "from darshan.experimental.plots.matplotlib import plot_access_histogram\n",
    "plot_access_histogram(r3, mod='POSIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\")\n",
    "r3.mod_read_all_records('MPI-IO')\n",
    "\n",
    "from darshan.experimental.plots.matplotlib import plot_access_histogram\n",
    "plot_access_histogram(r3, mod='MPI-IO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import darshan\n",
    "darshan.enable_experimental(verbose=False)\n",
    "\n",
    "r3 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/example.darshan\")\n",
    "r3.read_all()\n",
    "\n",
    "from darshan.experimental.plots.matplotlib import plot_opcounts\n",
    "plot_opcounts(r3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DXT Records\n",
    "\n",
    "DXT records are also supported, and can be loaded individually on a per module basis as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import darshan\n",
    "\n",
    "report2 = darshan.DarshanReport(\"/projects/Performance/chunduri/Software/Temp/darshan/darshan-util/pydarshan/examples/example-logs/dxt.darshan\")\n",
    "report2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report2.records['DXT_POSIX'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is easier to visualize or transform data to get an overview:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load prepared transformations\n",
    "# might require: pip install pillow\n",
    "from darshan.experimental.transforms.dxt2png import segment, wallclock\n",
    "\n",
    "report2.mod_read_all_dxt_records(\"DXT_POSIX\", dtype=\"dict\")  # need dict format for now\n",
    "rec = report2.records['DXT_POSIX'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallclock(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "report2.mod_read_all_dxt_records(\"DXT_POSIX\", dtype=\"pandas\") \n",
    "\n",
    "print(\"Write Segments:\")\n",
    "display(report2.records['DXT_POSIX'][2]['write_segments'])\n",
    "print(\"Read Segments:\")\n",
    "display(report2.records['DXT_POSIX'][2]['read_segments'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise left for the reader ;P \n",
    "Implement a custom aggregator/summary function and commit it as a contribution to pydarshan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create file: <darshan-repo>/darshan-util/pydarshan/darshan/experimental/aggregators/dxt_summary.py\n",
    "from darshan.report import *\n",
    "\n",
    "def dxt_summary(self):\n",
    "    \"\"\"\n",
    "    Count records for every name record.\n",
    "\n",
    "    Args:\n",
    "        mod_name (str): \n",
    "\n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    counts = {}\n",
    "\n",
    "    for mod, records in self.records.items():\n",
    "        for rec in records:\n",
    "            if rec['id'] not in counts:\n",
    "                counts[rec['id']] = {'name': self.name_records[rec['id']], 'counts': {}}\n",
    "\n",
    "            if mod not in counts[rec['id']]['counts']:\n",
    "                counts[rec['id']]['counts'][mod] = 1\n",
    "            else:\n",
    "                counts[rec['id']]['counts'][mod] += 1\n",
    "\n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Data for Use in Third-Party Analysis\n",
    "\n",
    "Darshan logs may be used in contexts beyond our imagination. To make this effortless export in JSON is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import darshan\n",
    "report = darshan.DarshanReport(\"example-logs/example.darshan\", read_all=True)\n",
    "report.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling?\n",
    "\n",
    "Currently, playing with two modes, both have their pros and cons.\n",
    "\n",
    "Generally, should expose errors and let users handle them. At the same time, just skipping invalid load requests does little harm but greatly improves convienince.\n",
    "\n",
    "Could add a switch to enable disable these guards :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = darshan.DarshanReport(\"example-logs/example.darshan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_records(\"ABC\") # Expect KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.mod_read_all_dxt_records(\"ABC\") # Expect warning, but not exception"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
